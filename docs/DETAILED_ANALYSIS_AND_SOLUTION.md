# DETAYLI ANALÄ°Z VE Ã‡Ã–ZÃœM STRATEJÄ°SÄ°

## ğŸ“Š MEVCUT DURUM ANALÄ°ZÄ°

### âŒ Sorun: Model Ã–ÄŸrenemiyor (Y-Loss Olmasa Bile)

**GÃ¶zlemler:**
- Prediction'lar GT ile Ã§akÄ±ÅŸmÄ±yor
- Zigzag yapÄ±yor (dÃ¼zensiz)
- SarÄ± Ã§izgi (merkez ekseni) hala var
- Lane'ler GT'den Ã§ok uzak
- Posterior collapse devam ediyor

---

## ğŸ” KÃ–K NEDEN ANALÄ°ZÄ°

### 1. **VISUAL TOKEN SAYISI - Ã‡OK FAZLA NOISE**

**Mevcut Durum (v4_fixed):**
- Full FPN: P3 (100x40) + P4 (50x20) + P5 (25x10)
- Toplam visual tokens: **~6,500 tokens**
- Her token spatial bilgi taÅŸÄ±yor ama Ã§oÄŸu gereksiz

**BaÅŸarÄ±lÄ± Overfit (0.26 loss):**
- P5 Only: (25x10) = **250 tokens**
- Ã‡ok daha az noise, model odaklanabiliyor

**Problem:**
- 6,500 token â†’ Cross-attention uniform oluyor
- Model hangi token'a bakacaÄŸÄ±nÄ± bilemiyor
- Information bottleneck: Ã‡ok fazla bilgi = hiÃ§ bilgi yok

**Ã‡Ã¶zÃ¼m:**
- P5 Only'e geri dÃ¶n (250 tokens)
- VEYA visual token'larÄ± subsample et (her 2x2'den 1 token al)
- VEYA attention pooling ekle (spatial attention ile Ã¶nemli token'larÄ± seÃ§)

---

### 2. **CROSS-ATTENTION MASKING - YANLIÅ KULLANIM**

**Mevcut Durum:**
```python
# libs/models/lanelm/model.py line 312-318
attn_out, _ = self.cross_attn(
    tgt,
    memory,
    memory,
    key_padding_mask=memory_key_padding_mask,  # â† Bu None olabilir!
    need_weights=False,  # â† Attention weights gÃ¶rmÃ¼yoruz!
)
```

**Problem:**
- `need_weights=False` â†’ Attention'Ä± debug edemiyoruz
- `memory_key_padding_mask` None ise â†’ TÃ¼m token'lara eÅŸit aÄŸÄ±rlÄ±k
- Attention uniform mu deÄŸil mi bilmiyoruz

**Ã‡Ã¶zÃ¼m:**
- `need_weights=True` yap
- Attention weights'i logla (uniformity score)
- EÄŸer uniform ise â†’ Visual encoder sorunlu

---

### 3. **LEARNING RATE - YÃœKSEK OLABÄ°LÄ°R**

**Mevcut Durum:**
- LR = 3e-4
- Gradient clipping = 1.0

**BaÅŸarÄ±lÄ± Overfit:**
- LR = 3e-4 â†’ 1e-6 (Cosine Annealing)
- Gradient clipping = 0.5

**Problem:**
- 3e-4 sabit LR â†’ Model Ã§ok hÄ±zlÄ± Ã¶ÄŸrenmeye Ã§alÄ±ÅŸÄ±yor
- Gradient clipping 1.0 â†’ Ã‡ok bÃ¼yÃ¼k adÄ±mlar
- Model "overshoot" yapÄ±yor, optimum'u kaÃ§Ä±rÄ±yor

**Ã‡Ã¶zÃ¼m:**
- LR = 1e-4 veya 5e-5 (daha konservatif)
- Gradient clipping = 0.5 (daha sÄ±kÄ±)
- Cosine Annealing ekle (LR yavaÅŸÃ§a dÃ¼ÅŸsÃ¼n)

---

### 4. **Y-LOSS WEIGHT - YANLIÅ AÄIRLIK**

**Mevcut Durum:**
- Loss = 0.7 * loss_x + 0.3 * loss_y

**Problem:**
- Y-loss eklenmiÅŸ ama model adapte olamamÄ±ÅŸ
- X ve Y'yi birlikte Ã¶ÄŸrenmek zor
- Model "confused" oluyor

**Ã‡Ã¶zÃ¼m (AÅŸamalÄ±):**
1. **AÅŸama 1:** Sadece X-loss (Y-loss = 0)
   - Model X'i Ã¶ÄŸrensin
   - Loss < 0.1 olana kadar bekle
2. **AÅŸama 2:** Y-loss ekle (weight = 0.1)
   - X zaten Ã¶ÄŸrenilmiÅŸ
   - Y'yi yavaÅŸÃ§a ekle
3. **AÅŸama 3:** Y-loss weight'i artÄ±r (0.1 â†’ 0.3)

---

### 5. **VISUAL ENCODER - LAYERNORM YETERLÄ° DEÄÄ°L**

**Mevcut Durum:**
```python
# libs/models/lanelm/model.py line 217
x = norm(x)  # LayerNorm
x = proj(x)  # Linear projection
```

**Problem:**
- CLRerNet FPN Ã§Ä±ktÄ±larÄ± Ã§ok bÃ¼yÃ¼k deÄŸerler iÃ§eriyor
- LayerNorm normalize ediyor ama yeterli deÄŸil
- Feature scale mismatch: FPN features vs. learned embeddings

**Ã‡Ã¶zÃ¼m:**
- LayerNorm'dan SONRA scale factor ekle (Ã¶rn. 0.1)
- VEYA FPN features'Ä± normalize et (mean=0, std=1)
- VEYA visual encoder'a residual connection ekle

---

### 6. **TOKENIZATION - ABSOLUTE MODE DOÄRU MU?**

**Mevcut Durum:**
- `x_mode="absolute"`
- `nbins_x=200`

**Problem:**
- Absolute mode: Her X koordinatÄ± baÄŸÄ±msÄ±z token
- Model her token'Ä± ayrÄ± Ã¶ÄŸrenmek zorunda
- Spatial continuity yok (bir Ã¶nceki token'dan baÄŸÄ±msÄ±z)

**BaÅŸarÄ±lÄ± Overfit:**
- `x_mode="relative_disjoint"`
- `max_abs_dx=32`
- Spatial continuity var (delta Ã¶ÄŸreniyor)

**Ã‡Ã¶zÃ¼m:**
- Relative mode'a geri dÃ¶n (spatial continuity iÃ§in)
- VEYA absolute mode'da positional encoding'i gÃ¼Ã§lendir

---

### 7. **TEACHER FORCING - EXPOSURE BIAS**

**Mevcut Durum:**
- Pure teacher forcing (scheduled sampling yok)
- `x_in[:, 1:] = x_tokens[:, :-1]` (GT'yi input olarak ver)

**Problem:**
- Training'de GT gÃ¶rÃ¼yor, inference'da kendi prediction'Ä±nÄ± gÃ¶rÃ¼yor
- Exposure bias: Training ve inference farklÄ±
- Model kendi hatalarÄ±nÄ± dÃ¼zeltmeyi Ã¶ÄŸrenemiyor

**Ã‡Ã¶zÃ¼m:**
- Scheduled sampling ekle (probability ile GT veya prediction kullan)
- VEYA inference-time training (inference sÄ±rasÄ±nda da train et)

---

### 8. **BATCH SIZE - Ã‡OK KÃœÃ‡ÃœK OLABÄ°LÄ°R**

**Mevcut Durum:**
- Overfit-size=1 â†’ Batch size deÄŸiÅŸken (kaÃ§ lane varsa)

**Problem:**
- Batch size Ã§ok kÃ¼Ã§Ã¼k â†’ Gradient noise yÃ¼ksek
- Model stabil Ã¶ÄŸrenemiyor

**Ã‡Ã¶zÃ¼m:**
- Batch size'Ä± sabitle (Ã¶rn. 4-8 lane)
- Gradient accumulation kullan

---

## ğŸ¯ Ã‡Ã–ZÃœM STRATEJÄ°SÄ° (Ã–NCELÄ°K SIRASI)

### **STRATEJÄ° 1: P5 ONLY + SADECE X-LOSS (EN HIZLI)**

**DeÄŸiÅŸiklikler:**
1. Full FPN â†’ P5 Only (250 tokens)
2. Y-loss'u kaldÄ±r (sadece X-loss)
3. LR = 1e-4, Gradient clipping = 0.5
4. Cosine Annealing ekle
5. Attention weights'i logla (uniformity check)

**Beklenen SonuÃ§:**
- Loss < 0.1 (overfit-size=1 iÃ§in)
- Prediction'lar GT ile Ã§akÄ±ÅŸmalÄ±
- Zigzag azalmalÄ±

**Test:**
```bash
python tools/train_lanelm_v4_fixed.py --overfit-size 1 --epochs 500 --lr 1e-4
```

---

### **STRATEJÄ° 2: VISUAL TOKEN SUBSAMPLING (ORTA VADELÄ°)**

**DeÄŸiÅŸiklikler:**
1. Full FPN kullan ama subsample et
   - P3: Her 2x2'den 1 token (100x40 â†’ 50x20)
   - P4: Her 2x2'den 1 token (50x20 â†’ 25x10)
   - P5: TÃ¼mÃ¼nÃ¼ kullan (25x10)
   - Toplam: ~1,500 tokens (6,500'den daha az)
2. Attention pooling ekle (spatial attention ile Ã¶nemli token'larÄ± seÃ§)

**Beklenen SonuÃ§:**
- Full FPN bilgisini korur ama noise azalÄ±r
- Model daha iyi Ã¶ÄŸrenir

---

### **STRATEJÄ° 3: RELATIVE TOKENIZATION + SPATIAL CONTINUITY (UZUN VADELÄ°)**

**DeÄŸiÅŸiklikler:**
1. Absolute â†’ Relative mode
2. `max_abs_dx=32` (kÃ¼Ã§Ã¼k delta)
3. Spatial continuity iÃ§in positional encoding gÃ¼Ã§lendir

**Beklenen SonuÃ§:**
- Zigzag azalÄ±r (spatial continuity sayesinde)
- Model daha smooth prediction yapar

---

## ğŸ“‹ DETAYLI CHECKLIST

### âœ… HEMEN YAPILACAKLAR

- [ ] **P5 Only'e geri dÃ¶n** (Full FPN â†’ P5 Only)
- [ ] **Y-loss'u kaldÄ±r** (sadece X-loss)
- [ ] **LR dÃ¼ÅŸÃ¼r** (3e-4 â†’ 1e-4)
- [ ] **Gradient clipping sÄ±kÄ±laÅŸtÄ±r** (1.0 â†’ 0.5)
- [ ] **Cosine Annealing ekle**
- [ ] **Attention weights logla** (uniformity check iÃ§in)

### âš ï¸ SONRA YAPILACAKLAR

- [ ] Visual token subsampling
- [ ] Attention pooling
- [ ] Scheduled sampling
- [ ] Relative tokenization

---

## ğŸ”¬ DEBUG ADIMLARI

### 1. **Attention Uniformity Check**
```python
# libs/models/lanelm/model.py'de
attn_out, attn_weights = self.cross_attn(..., need_weights=True)
# attn_weights: (B, num_heads, T, N)
uniformity = compute_uniformity_score(attn_weights)
print(f"Attention Uniformity: {uniformity}")
# EÄŸer > 0.95 â†’ Uniform, model gÃ¶rsel bilgiyi kullanmÄ±yor!
```

### 2. **Visual Token Statistics**
```python
# Visual token'larÄ±n mean/std'ini logla
print(f"Visual tokens mean: {visual_tokens.mean()}, std: {visual_tokens.std()}")
# EÄŸer Ã§ok bÃ¼yÃ¼kse â†’ Normalize et
```

### 3. **Gradient Norm Check**
```python
# Gradient norm'larÄ± logla
total_norm = torch.nn.utils.clip_grad_norm_(lanelm.parameters(), max_norm=1.0)
print(f"Gradient norm: {total_norm}")
# EÄŸer Ã§ok bÃ¼yÃ¼kse â†’ LR dÃ¼ÅŸÃ¼r veya clipping artÄ±r
```

---

## ğŸ“Š BEKLENEN SONUÃ‡LAR

### **BaÅŸarÄ± Kriterleri:**
1. **Loss < 0.1** (overfit-size=1 iÃ§in)
2. **Attention Uniformity < 0.5** (model gÃ¶rsel bilgiyi kullanÄ±yor)
3. **Prediction'lar GT ile Ã§akÄ±ÅŸÄ±yor** (pixel error < 5px)
4. **Zigzag yok** (smooth prediction'lar)

### **BaÅŸarÄ±sÄ±zlÄ±k Durumu:**
- Loss > 1.0 â†’ Model mimarisi sorunlu
- Attention Uniformity > 0.95 â†’ Visual encoder sorunlu
- Prediction'lar hala GT'den uzak â†’ Tokenization veya loss function sorunlu

---

## ğŸ“ SONUÃ‡

**Ana Problem:** Visual token sayÄ±sÄ± Ã§ok fazla (6,500) â†’ Model hangi token'a bakacaÄŸÄ±nÄ± bilemiyor â†’ Cross-attention uniform â†’ Posterior collapse

**Ana Ã‡Ã¶zÃ¼m:** P5 Only'e geri dÃ¶n (250 tokens) â†’ Model odaklanabiliyor â†’ Cross-attention meaningful â†’ Model Ã¶ÄŸreniyor

**Sonraki AdÄ±m:** P5 Only ile baÅŸarÄ±lÄ± olduktan sonra, Full FPN'i subsample ederek geri ekleyebiliriz.

